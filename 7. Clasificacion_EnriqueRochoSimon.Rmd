---
title: 'Algoritmos de clasificación: SVM, Árboles de decisión simples y múltiples (random forest)'
author: "ENRIQUE ROCHO SIMON"
date: "Enero 2023"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header:
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

******
# Introducción
******

## Descripción de la PEC a realizar
La prueba está estructurada en 6 ejercicios teórico-prácticos que piden que se desarrolle la fase de preparación y estimación de un modelo supervisado utilizando un juego de datos.  

Deben responderse al menos 4 de los 6 ejercicios para poder superar la PEC. Para optar a la máxima nota tienen que responderse todos los ejercicios de forma correcta.  

## Criterios de evaluación
**Ejercicios teóricos**  
Todos los ejercicios deben ser presentados de forma razonada y clara. No se aceptará ninguna respuesta que no esté claramente justificada.  

**Ejercicios prácticos**  
Para todas las PEC es necesario documentar en cada ejercicio práctico qué se ha hecho y cómo se ha hecho.  

Pregunta  | Criterio de valoración| Peso
---- | ------------- | ----
1  | Se realiza el primer gráfico | 5%
1  | El primer gráfico tiene los colores y formas adecuados | 5%
1  | Se realiza el segundo gráfico | 5%
1  | El segundo gráfico tiene los colores y formas adecuados | 5%
2  | Se entrena el modelo de la familia RandomForest que no es RF | 5%
2  | Se muestra la matriz de confusión | 5%
2  | Se define la Sensibilidad | 5%
2  | Se analizano los valores de Sensibilidad de las 3 clases | 5%
3  | Se entrena el modelo solicitado | 10%
3  | Se compara el resultado con el otro modelo | 5%
4  | Se entrena el modelo | 5%
4  | Se evalua el modelo | 5%
4  | Se representa gráficamente | 5%
4  | Se describen todas las reglas | 5%
4  | Se razona la respuesta | 5%
5  | Se elige una variante y se describe | 5%
5  | Se entrena el modelo variante | 5%
5  | Se muestra la matriz de confusión | 5%
5  | Se compara con el modelo SVMLineal | 5%
-  | Se incluye bibliografía utilizada en todos los ejercicios| 5% (Adicional)

## Formato y fecha de entega
El formato de entrega es: studentname-PECn.html  
Fecha de Entrega: 08/01/2023  
Se debe entregar la PEC en el buzón de entregas del aula  


******
# Base teórica
******

Esta práctica se basa en un ejemplo de **algoritmos de clasificación**. Durante la práctica se ilustran conceptos generales de metodologías de clasificación de algoritmos así como algunas técnicas habituales como son **SVM** y **Árboles de decisión**.  

Cuando se trabajan con algoritmos de clasificación supervisados, es importante preparar de forma adecuada los conjuntos de entrenamiento (train set) y validación (validation set o test set). Los modelos se entrenan estrictamente con el conjunto de entrenamiento y, a continuación, se valida el modelo resultante sobre el conjunto de validación. Lo habitual es que el algoritmo funcione mejor con los datos de entrenamiento que con los datos de validación (que nunca ha visto antes). Si la diferencia entre la capacidad predictiva en el conjunto de entrenamiento es muy superior a la capacidad predictiva en el conjunto de validación estamos ante un problema de sobreajuste o sobreentrenamiento (**overfitting**) y es uno de los puntos clave a tener en cuenta cuando se implementa un sistema de clasificación. Si la capacidad predictiva en ambos conjuntos es similar, esta métrica refleja la capacidad del modelo de generar resultados correctos frente a datos a los que no ha estado expuesto previamente.

**SVM (Support Vector Machines o máquinas de soporte vectorial)** tiene como objetivo encontrar el hiperplano óptimo que maximiza el margen entre clases (variable objetivo) del juego de datos de entrenamiento. Definiremos el margen como la zona de separación entre los distintos grupos a clasificar. Esta zona de separación quedará delimitada a través de hiperplanos. Las SVM buscan maximizar el margen entre los puntos pertenecientes a los distintos grupos a clasificar. Maximizar el margen implica que el hiperplano de decisión o separación esté diseñado de tal forma que el máximo número de futuros puntos queden bien clasificados 

Los **Árboles de decisión** son algoritmos que construyen modelos de decisión que forman estructuras similares a los diagramas de flujo, donde los nodos internos suelen ser puntos de decisión sobre un atributo del juego de datos. Son muy dependientes del concepto de ganancia de la información ya que es el criterio que utilizan para construir las ramificaciones del árbol.
A grandes rasgos existen dos tipos de árboles de decisión:
* _Árboles de decisión simples_: el resultado se construye mediante un proceso de clasificación.
* _Árboles de decisión múltiples (random forest)_: el resultado se construye mediante el desarrollo iterativo de *n* procesos de clasificación.
 
Aparte de los modelos propuestos en esta práctica, existe una gran variedad de alternativas de distinta complejidad, como los **modelos lineales generalizados** o **redes neuronales**.

**Recursos en la web:**  

* [Wikipedia: K-NN (k-vecinos más cercanos)](https://es.wikipedia.org/wiki/K-vecinos_m%C3%A1s_cercanos)  
* [Wikipedia: Árbol de decisión simple](https://es.wikipedia.org/wiki/%C3%81rbol_de_decisi%C3%B3n)  
* [Wikipedia: Árbol de decisión múltiple (Random forest)](https://es.wikipedia.org/wiki/Random_forest))  

* [A Detailed Introduction to K-Nearest Neighbor (K-NN) Algorithm](https://saravananthirumuruganathan.wordpress.com/2010/05/17/a-detailed-introduction-to-k-nearest-neighbor-knn-algorithm/)  

* [A Brief Tour of the Trees and Forests](http://www.r-bloggers.com/a-brief-tour-of-the-trees-and-forests/)  

* [Linear classifiers] https://en.wikipedia.org/wiki/Linear_classifier
* [Generalized linear models] https://es.wikipedia.org/wiki/Modelo_lineal_generalizado
* [Kernel methods & SVM] https://en.wikipedia.org/wiki/Kernel_method
* [Neural networks] https://en.wikipedia.org/wiki/Artificial_neural_network

******
# Caso de estudio: Clasificación red de ventas Bodegas Mureda  
******
Formamos parte de la Dirección Comercial de la Bodega de vinos **Mureda** y queremos analizar la actividad de nuestra red de ventas, formada por tres categorías de comerciales (A, B y C). Para ello, estamos interesados en conocer:

* si existen diferencias en la actividad generada por cada uno de los comerciales
 
* en caso afirmativo:
  
  * identificar cuáles son las variables que más contribuyen a dichas diferencias
  
  * predecir a qué categoría de comercial pertenece un nuevo empleado en función de su actividad. 

Para ello, nuestro equipo de análisis dispone de un fichero con información de 150 clientes que recoge estadísticas de actividad de los tres grupos de Comerciales, a razón de 50 registros por grupo de comercial. El fichero contiene información de las siguientes variables:  

* _Importe_: Volumen de Facturación en el Cliente (vinculado a una categoría de Comercial)  

* _Margen_: Margen por Cliente (vinculado a una categoría de Comercial)  

* _Km_: Kilómetros recorridos para visitar al Cliente.

* _Visitas_: Visitas realizadas al Cliente.

* _Comercial_: Categoría de comercial asignada al cliente (Toma valores A, B ó C)  



Una vez definidos los objetivos de nuestra investigación, nuestro departamento de análisis nos propone desarrollar un proceso de clasificación que aplique distintos modelos y que estudiemos qué algoritmos nos permiten extraer mejores resultados sobre nuestro conjunto de datos.


******
# Apartados de la práctica
******
El código R que utilizaremos en la práctica se divide en apartados según las tareas que iremos realizando:  

**Apartados práctica:**  

* Carga de paquetes necesarios y fichero  

* Análisis univariable y bivariable de los datos  

    + Descriptivos de las variables del fichero  
    
    + Estudio de la relación entre variables  
    
    + Comparación de las variables por tipo de Comercial  
    
* Preparación de los conjuntos de entrenamiento y validación

* Clasificación de los clientes con _SVM_ 

    + Construcción del Modelo de clasificación con _SVM_  
    
    + Validación del Modelo de clasificación con _SVM_  
    
* Clasificación de los clientes con árboles de decisión simples  

    + Construcción del Modelo de clasificación con el paquete _rpart_  
    
    + Validación del Modelo de clasificación con el paquete _rpart_  
    
* Clasificación de los clientes con árboles de decisión múltiples (_random forest_)  

    + Construcción del Modelo de clasificación con el paquete _randomForest_  
    
    + Validación del Modelo de clasificación con el paquete _randomForest_  

******
# Carga de paquetes y del fichero de datos
******
Empezaremos por cargar los packages R que necesitaremos tener en memoria. Es importante recordar que las librerías que no se carguen e indiquen el error: "Error in library("XXXX") : there is no package called ‘XXXX’", deberán ser instaladas con el comando install.packages("XXXX")

Cargamos también los datos ubicados en el fichero PEC3.csv 

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# Cargamos los paquetes necesarios para desarrollar la PEC

#   Para representar gráficamente la relación entre variables
library("ggplot2")
#   Para clasificar con SVM
library('e1071')
#   Para clasificar con K-NN
library("class")
#   Para clasificar con rpart
library("rpart")
library("rpart.plot")
library("useful")
#   Para clasificar con randomForest
library("randomForest")
# Libreria que permite clasificar con SVM, KNN, Arboles de decisión y RandomForest entre otros
library("caret")

setwd("E:/Análisis de datos/Fundamentos Data Science/PEC3/")

#No funciona la carga con getwd()
#nombreruta_PEC <- paste(getwd(),'E:/Análisis de datos/Fundamentos Data Science/PEC3/PEC3.csv', sep = "")

# Cargamos el fichero de datos que utilizamos para desarrollar la PEC:
nombreruta_PEC <- paste('E:/Análisis de datos/Fundamentos Data Science/PEC3/PEC3.csv', sep = "")

Data_PEC <- read.csv(nombreruta_PEC, encoding="UTF-8", stringsAsFactors = TRUE,
                      header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE)
```

******
# Análisis univariable y bivariable del fichero
******

La primera fase del análisis consiste siempre en un análisis descriptivo de las variables incluidas en el fichero y de la relación existente entre ellas. Para ello, aplicamos la siguiente secuencia de cálculos y representaciones gráficas.

1. Estadísticos descriptivos de las variables
2. Representación gráfica de cada una de las variables 
3. Estudio de la relación entre las variables cuantitativas
4. Estudio de la existencia de diferencias por comercial

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# 1.Calculamos los descriptivos univariables de las variables del fichero
summary(Data_PEC) #Estadísticos descriptivos básicos de las variables
```

Algunos de los estadísticos descriptivos de posición que caracterizan a las 5 variables son: 

* _Importe_: Promedio de 5.843, Máximo 7.900, Mínimo 4.300  

* _Margen_: Promedio de 305,4, Máximo 440, Mínimo 200  

* _Km_: Promedio de 37,59, Máximo 69, Mínimo 10  

* _Visitas_: Promedio de 11,99, Máximo 25, Mínimo 1

* _Comercial_: 50 observaciones por comercial  


```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}

# 2.Representamos gráficamente las variables del fichero mediante histogramas

#Histograma Ingresos
f1 <- hist(Data_PEC$Ingresos, main="Histograma Ingresos", col = "gray", labels = TRUE) 
f1
#Histograma Margen
f2 <- hist(Data_PEC$Margen, main="Histograma Margen", col = "gray", labels = TRUE)
f2
#Histograma Km
f3 <- hist(Data_PEC$Km, main="Histograma Km", col = "gray", labels = TRUE)
f3
#Histograma Visitas
f4 <- hist(Data_PEC$Visitas, main="Histograma Visitas", col = "gray", labels = TRUE)
f4
#Histograma Comercial
f5 <- plot(Data_PEC$Comercial)
f5
```

Las variables cuantitativas presentan dos distribuciones diferenciadas:  

* _Importe_ y _Margen_ presentan una distribución similar a una campana de _Gauss_, algo más concentrada en el caso de _Margen_  

* _Km_ y _Visitas_ presentan una distribución muy similar. Con una alta concentración para valores bajos que desciende rápidamente para volver a crecer siguiendo una campana de _Gauss_ a partir del tercer valor de la serie.  


```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# 3.Estudiamos la relación existente entre las variables del fichero

# Estudiamos la relación entre variables mediante gráficos de dispersión
f6<- plot(Data_PEC)                                              
# Estudiamos la relación entre variables cuantitativas mediante correlaciones
cor(Data_PEC[,c("Ingresos","Margen","Km","Visitas")], use="complete")
```

Analizando los gráficos de dispersión, apuntamos una fuerte relación entre _Visitas_-_Km_, _Ingresos_-_Km_, _Margen_-_Km_ e _Ingresos_-_Visitas_ que podemos validar con el coeficiente de correlación, estadístico que toma valores entre -1 y 1 y que mide la fuerza con la que dos variables quedan interrelacionadas (próximo a 1 cuando la relación es fuertemente directa y próximo a -1 cuando la relación es fuertemente inversa)  


* Coeficiente de Correlación _Visitas_-_Km_ -> (0,96)  

* Coeficiente de Correlación _Ingresos_-_Km_ -> (0,87)  

* Coeficiente de Correlación _Ingresos_-_Visitas_ -> (0,82)  

* Coeficiente de Correlación _Margen_-_Km_ -> (-0,42)  

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# Estudiamos la relación entre variables Km y Visitas
f7<-ggplot(Data_PEC, aes(x=Km, y=Visitas)) + geom_point()
f7
# Estudiamos la relación entre variables Km y Visitas con tamañoo ingresos
f8<-ggplot(Data_PEC, aes(x=Km, y=Visitas)) + geom_point(aes(size=Ingresos))
f8
# Relación entre variables Km y Visitas con tamaño margen
f9<-ggplot(Data_PEC, aes(x=Km, y=Visitas)) + geom_point(aes(size=Margen))
f9
# Relación entre variables Km y Visitas con tamaño margen
fA<-ggplot(Data_PEC, aes(x=Km, y=Margen)) + geom_point(aes(size=Ingresos))
fA

# 3.Estudiamos la existencia de diferencias por Comercial

# promedio variables por comercial 
tapply(Data_PEC$Ingresos,Data_PEC$Comercial,mean)
tapply(Data_PEC$Margen,Data_PEC$Comercial,mean)
tapply(Data_PEC$Km,Data_PEC$Comercial,mean)
tapply(Data_PEC$Visitas,Data_PEC$Comercial,mean)
```

Vemos que existen diferencias remarcables en el promedio de cada una de las variables para cada Comercial:  

* El Comercial C es el Comercial con un _Importe_ promedio mayor, con una valor ligeramente superior al de B  
* El Comercial A es el Comercial con un _Margen_ promedio mayor  

* El Comercial C es el Comercial que hace más _Visitas_ en promedio  

* El Comercial C es el Comercial que hace más _Km_ en promedio, con un valor que es prácticamente el doble que el del B  


Graficamos a continuación las variables cuantitativas diferenciando por Comercial.

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# Relación entre variables Km y Visitas con tamaño ingresos y Color según Comercial
f10<-ggplot(Data_PEC, aes(x=Km, y=Visitas, color=Comercial)) + geom_point(aes(size=Ingresos))
f10
# Relación entre variables Km y Visitas con tamaño ingresos y Color según Comercial, línea tendencia y elipse
f11<-ggplot(Data_PEC, aes(x=Km, y=Visitas, color=Comercial)) + geom_point(aes(size=Ingresos)) + geom_smooth(method=lm, aes(fill=Comercial))+ stat_ellipse(type = "norm")
f11
```

Identificamos un comportamiento diferenciado donde _Km_ y _Visitas_ ya que son las variables que presentan una mayor capacidad de diferenciación.


******
# Preparación de los conjuntos de entrenamiento y validación
******

Construimos un **juego de datos de entrenamiento** con el 70% de registros para construir los modelos y un **juego de datos de pruebas o validación** con el 30% de registros restantes para validar los modelos. Esta separación de ambos conjuntos es aleatoria.

Separamos los datos en entrenamiento y validación antes de proceder con el resto de ejercicios para asegurar que los datos de entrenamiento y validación son iguales en todos los casos y los resultados son comparables. Si lo hiciésemos de otro modo, las diferencias en la calidad de los modelos podrían ser debidas a una separación distinta entre los conjuntos de entrenamiento y validación.

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# Dividimos el fichero en 70% entreno y 30% validación  #
RNGversion('3.5.3') # fijaremos el criterio de generación de números aleatorios para que todos obtengamos los mismos resultados 
set.seed(1234)  # Seed inicializa el generador de números aleatorios que usaremos para separar los datos en train y test. Usando un seed fijo, nos aseguramos de que todos generamos los mismos conjuntos y los resultados son reproducibles
ind <- sample(2, nrow(Data_PEC), replace=TRUE, prob=c(0.7, 0.3))
trainData <- Data_PEC[ind==1,]
testData <- Data_PEC[ind==2,]
```


******
# Proceso de clasificación mediante SVM utilizando el paquete e1071.
******

**Aplicamos el modelo SVM**, pasándole como parámetros la matriz de entrenamiento compuesta por las 4 variables cuantitativas : _Importe_, _Margen_, _Km_ y _Visitas_. No le pasamos el campo _Comercial_ porque precisamente es el campo que el algoritmo debe predecir.  


```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# Entrenamos el modelo SVM
model_svm = svm(trainData[,1:4], trainData$Comercial)
# Usamos el modelo que hemos entrenado para generar una predicción para cada muestra del conjunto de validación 
preds_svm = predict(model_svm, testData[,1:4])
# Calculamos el % de aciertos de nuestro modelo
sum(preds_svm == testData$Comercial)/ length(testData$Comercial)*100
```

Evaluamos el % de acierto del modelo SVM que hemos entrenado. 

SVM genera un 94.73% de acierto sobre los datos propuestos.


******
# Proceso de clasificación mediante SVM utilizando el paquete caret
******

Comenzamos entrenando el modelo SVM lineal con el paquete caret

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# Modelo SVM Lineal
svm.caret <- train(Comercial~., data=trainData, method = 'svmLinear', trControl = trainControl(method = "cv"))
svm.caret
```

En la salida del modelo podemos visualizar la capacidad predictiva del modelo mediante las métricas Accuracy y Kappa en el conjunto de entrenamiento. Adicionalmente vamos a calcular la matriz de confusión sobre el conjunto de test para poder profundizar más y descartar el overfitting.

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# Realizamos las predicciones del modelo sobre el conjunto de test
preds_svm.caret<-predict(svm.caret, testData) 
# Matriz de confusión
confusionMatrix(preds_svm.caret,testData$Comercial) 
```

Vemos que el acierto es similar al del conjunto de entrenamiento descartando el overfitting y podemos apreciar tanto las métricas generales del modelo como las métricas particulares de cada una de las categorías.

******
# Proceso de clasificación mediante Árboles de decisión simples
******

Para construir un árbol de decisión es necesario definir una función que relaciona una variable categórica dependiente (factor) con _n_ variables independientes que pueden ser categóricas o numéricas. En nuestro caso trabajaremos con:  

* 1 variable factor dependiente -> _Comercial_  

* 4 variables independientes -> _Ingresos_, _Margen_, _Km_ y _Visitas_  


El algoritmo de clasificación busca cuál es la variable que permite obtener una submuestra más diferenciada para la variable dependiente (_Comercial_ en nuestro caso) e identifica también qué intervalos (si la variable es cuantitativa) ó agrupación de categorías de la/s variable/s independiente/s permitiría/n maximizar dicha división. 

Una vez identificada la variable independiente que permite obtener la clasificación con una mayor capacidad de diferenciación, el proceso se repite reiterativamente en cada uno de los nodos obtenidos hasta que el algoritmo no encuentra diferencias significativas que le permitan seguir profundizando en los nodos. 

Una vez obtenido una primera versión del árbol, existen algoritmos que permiten hacer un podado del árbol (_prunning_), eliminando aquellas ramas que no acaban de justificar su presencia de acuerdo con algunos parámetros preestablecidos.  

En todos los casos seguiremos la siguiente secuencia de pasos para obtener los Árboles de clasificación:  

1. Definir la función que relaciona la variable dependiente con las variables independientes  

2. Estimar el árbol de decisión  

3. Representar gráficamente una primera versión del árbol  

  + Estudiar la aplicación práctica del resultado obtenido  
  
  + Podar el árbol (si el algoritmo admite podado)  
  
4. Estudiar la capacidad predictiva del árbol  


Estudiamos a continuación la capacidad predictiva del Árbol de decisión simple obtenido mediante el paquete *rpart*

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# Declaramos función del árbol
ArbolRpart = Comercial ~ Ingresos + Margen + Km + Visitas
# Aplicamos algoritmo
model_tree = rpart(ArbolRpart, method="class", data=trainData)
# Validamos la capacidad de predicción del árbol con el fichero de validación
preds_tree <- predict(model_tree, newdata = testData, type = "class")
# Visualizamos una matriz de confusión
table(preds_tree, testData$Comercial)
# Calculamos el % de aciertos 
sum(preds_tree == testData$Comercial)/ length(testData$Comercial)*100
```

El árbol de decisión obtenido mediante el paquete *rpart* clasifica correctamente un 94,73% de los registros. Un resultado bastante alto y aceptable.  
  
Una vez construida una primera versión del árbol, estudiamos la viabilidad de un podado de árbol.

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# Podado del árbol
pruned_tree_model <- prune(model_tree, cp= model_tree$cptable[which.min(model_tree$cptable[,"xerror"]),"CP"])
pruned_tree_model <- prune(pruned_tree_model, cp= 0.02)
# Representación del árbol podado
f14<-rpart.plot(pruned_tree_model,extra=4) #visualizamos el árbol
f14
```
  
Dado que el árbol original es muy simple. El podado no devuelve ninguna versión nueva reducida.
  
  
******
# Proceso de clasificación mediante Árboles de decisión simples utilizando el paquete caret
******

Comenzamos entrenando un modelo basado en arboles de decisión con el paquete caret utilizando una validación cruzada. Si leeis la documentación comprobaréis que se basan en la misma librería puesto que caret es un agregados y homogeneizador de múltiples algoritmos.

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# Modelo SVM Lineal
tree.caret <- train(Comercial~., data=trainData,method = 'rpart', trControl = trainControl(method = "cv"))
tree.caret
```

En la salida del modelo podemos visualizar la capacidad predictiva del modelo mediante las métricas Accuracy, Kappa y la complejidad paramétrica en el conjunto de entrenamiento. 

Podemos representar visualmente el modelo final seleccionado

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
plot(tree.caret$finalModel, uniform=TRUE,main="Classification Tree")
text(tree.caret$finalModel, use.na=TRUE, all=TRUE, cex=.8)
```

En este caso, vemos que la salida proporcionada por la librería rpart es más vistosa.


Adicionalmente vamos a calcular la matriz de confusión sobre el conjunto de test para poder profundizar más y descartar el overfitting.


```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# Realizamos las predicciones del modelo sobre el conjunto de test
preds_tree.caret<-predict(tree.caret, testData) 
# Matriz de confusión
confusionMatrix(preds_tree.caret,testData$Comercial) 
```
Vemos que el acierto es similar al del conjunto de entrenamiento descartando el overfitting y podemos apreciar tanto las métricas generales del modelo como las métricas particulares de cada una de las categorías.

******
# Proceso de clasificación mediante árboles de decisión múltiples (paquete randomForest)
******

Una vez evaluada la capacidad predictiva del algoritmo *SVM*, y los árboles de decisión simples obtenidos mediante el paquete *rpart*, estimamos el modelo que obtendríamos si ejecutásemos _n_ árboles de decisión simultáneamente (para _n_=100 en nuestro caso) mediante el algoritmo *randomForest*.

El algoritmo *randomForest* es un método de estimación combinado, donde el resultado de la estimación se construye a partir de los resultados obtenidos mediante el cálculo de _n_ árboles donde los predictores son incluidos al azar. 

Es un método complejo con ventajas e inconvenientes respecto a los árboles de clasificación simples:  

*Ventajas*  

* Es uno de los algoritmos de aprendizaje más precisos  

* Se ejecuta eficientemente en grandes bases de datos  

* Permite trabajar con cientos de variables independientes sin excluir ninguna  

* Determina la importancia en la clasificación de cada variable  

* Recupera eficazmente los valores perdidos de un dataset (_missings_)  

* Permite evaluar la ganancia en clasificación obtenida a medida que incrementamos el número de árboles generados en el modelo.  


*Inconvenientes*  

* A diferencia de los árboles de decisión, la clasificación hecha por _random forests_ es difícil de interpretar  

* Favorece las variables categóricas que tienen un mayor número de niveles por encima de aquéllas que tienen un número de categoría más reducido. Comprometiendo la fiabilidad del modelo para este tipo de datos.  

* Favorece los grupos más pequeños cuando las variables están correlacionadas  

* randomForest sobreajusta en ciertos grupos de datos con tareas de clasificación/regresión ruidosas  



  
```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
set.seed(123)
#Declaramos función del árbol
ArbolRF <- Comercial ~ Ingresos + Margen + Km + Visitas
#Aplicamos algoritmo
model_random_forest <- randomForest(ArbolRF, data=trainData, ntree=500,proximity=T,nodesize=5) #indicamos el número de árboles mediante ntree=500
#Obtenemos la importancia de cada variable en el proceso de clasificación
importance(model_random_forest)      #Importancia de las variables en formato text
f15<-varImpPlot(model_random_forest) #Importancia de las variables en formato gráfico
f15
#evolución del error según el número de árboles
f16<-plot(model_random_forest, main = "")  
head(f16)
# Validamos la capacidad de predicción del árbol con el fichero de validación
preds_random_forest <- predict(model_random_forest, newdata = testData)
table(preds_random_forest, testData$Comercial)
# Calculamos el % de aciertos 
sum(preds_random_forest == testData$Comercial)/ length(testData$Comercial)*100
```

El árbol de decisión obtenido mediante el paquete *randomForest* clasifica correctamente un 97,36% de los registros. Un resultado bastante alto y aceptable.  

******
# Ejercicios
******


## Pregunta 1

En el gráfico f10 mostramos la relación entre las variables Visitas, KM e Ingresos diferenciando por colores entre las categorías. Realice 2 gráficos similares que muestren las variables Km y Margen utilizando el dataset de validación testData. En el primer gráfico se tienen que colorear los elementos con su categoría real, en el segundo se tienen  que colorear con la prediccion realizada utilizando el modelo model_svm entrenado anteriormente. En ambos gráficos se tiene que mostrar si las predicciones son correctas o no utilizando formas distintas para los aciertos y para los fallos.

## Respuesta 1

> Podemos ver mediante los dos gráficos el cambio de la categoría "Comercial" real a las categorías predichas por el modelo con preds_svm. Efectivamente aparecen 2 elementos clasificados por smv como "C" que en realidad deberían ser "B".

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}

#Elementos con categoría real:
f22<-ggplot(testData, aes(x=Km, y=Margen, color=Comercial))+geom_point(aes(shape=preds_svm==Comercial))
f22

#Predicción:
f23<-ggplot(testData, aes(x=Km, y=Margen, color=preds_svm))+geom_point(aes(shape=preds_svm==Comercial))
f23


```

## Pregunta 2

Entrene un modelo de RandomForest mediante el paquete Caret que no sea el modelo rf (enlace: http://topepo.github.io/caret/train-models-by-tag.html y buscar la familia Random Forest) y muestre su matrix de confusión sobre el conjunto de test. Analice los valores de la métrica Sensitivity de cada una de las clases. ¿Qué es esa métrica? ¿Qué conclusiones obtiene de los resultados con respecto a esa métrica?

## Respuesta 2 

> Usamos el modelo Parallel Random Forest.

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}

#Cargamos librería:
library('e1071')

#Aplicamos train con el metodo parRF:
prueba.parRF <- train(Comercial~., data=trainData,method = 'parRF', trControl = trainControl(method = "cv"))
prueba.parRF

# Realizamos las predicciones del modelo sobre el conjunto de test:
preds_prueba.parRF<-predict(prueba.parRF, testData) 
# Matriz de confusión:
confusionMatrix(preds_prueba.parRF,testData$Comercial) 

```

>La Sensitivity se calcula como el número de predicciones positivas correctas dividido entre el total de positivas (que incluye las predicciones positivas correctas y las predicciones positivas incorrectas).
Se le puede llamar recall (REC) o true positive rate (TPR). La mejor sensitividad es 1, y la peor 0.
Sensitivity mide cómo de apto es el modelo para detectar eventos en la clase positiva.

>En el caso de este modelo entrenado, la clase "A" y "B" que nos dan 1, nos indican que el 100% de las categorías fueron correctamente predichas Sin embargo para la clase "C", con 0.8750, nos indica que un 87,5% de esta clase fue correctamente predecida como clase "C".



## Pregunta 3

Calcula una predicción de clasificación utilizando el algoritmo KNN con k=2. Compare los resultados con los obtenidos utilizando el modelo model_svm

## Respuesta 3


```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}

#Cargamos la librería:
library(caret)

#Establecemos la malla:
knnGrid <-  expand.grid(k = c(1:2))
#Entrenamos el Modelo knn:
knn.caret <- train(Comercial~., data=trainData ,method = "knn",tuneGrid = knnGrid)


#Realizamos la predicción del modelo entrenado:
pred_knn<-predict(knn.caret, testData)
confusionMatrix(pred_knn,testData$Comercial)

```
>Para knn el % de precisión es solo del 76% comparado con el 94% que tuvimos para svm.
Se han clasificado bien todas las clases "A", pero ha habido bastantes errores en "B" y "C".

>Vemos en efecto que Sensitivity es del 100% para "A", pero del 75% para "B" y del 62,5% para "C". 
>El valor Kappa para knn es del 0,6423. Para ser un modelo informativo debería estar más cercano a 1. En svm el valor es 0,92, por lo que es un modelo mucho más informativo.

>El p-valor también es más bajo en smv, lo que también demuestra que es un modelo más informativo.



## Pregunta 4

En el apartado **Proceso de Clasificación mediante árboles de decisión simple** se ha construido un árbol de decisión simple utilizando todas las variables.

Construya un árbol de decisión simple considerando sólo las variables Ingresos y Margen. 

Sin podarlo, evalúe el modelo y represente gráficamente el árbol. Describa las reglas de decisión finales para las hojas.

Suponiendo que no tenemos más variables y por lo tanto no se han podido entrenar los modelos previso, ¿qué opinión tiene del árbol? ¿resultaría de alguna utilidad? 

## Respuesta 4


```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
#Carga de librerías:

library("rpart")
library("rpart.plot")

# Declaramos la función del árbol:
ArbolIngMarg = Ingresos ~ Margen
# Aplicamos el algoritmo:
model_arb = rpart(ArbolIngMarg, method="class", data=trainData)

# Validamos la capacidad de predicción del árbol con el fichero de validación:
pred_arb <- predict(model_arb, newdata = testData, type = "class")

# Visualizamos una matriz de confusión:
table(pred_arb, testData$Ingresos)
# Calculamos el % de aciertos:
sum(pred_arb == testData$Ingresos)/ length(testData$Ingresos)*100

```

>Obtenemos un % de aciertos muy bajo, tan solo del 5,26%

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}

#visualizamos el árbol
f24<-rpart.plot(model_arb,extra=2) 
f24

```

>Respecto a la información obtenida con rpart.plot:
El árbol empieza en root con la etiqueta 1) que tiene 112 observaciones. Hay 104 observaciones que "No" serían el valor de Ingresos 5100, las probabilidades para este valor es de 0,018 y a continuación se dan las probabilidades para el resto de valores.
Debajo de root tenemos 2 ramas:
La rama 2), que nos indica Margen>=335. Tiene 28 observaciones, de las cuales 22 "No" serían Ingresos 5100 (el porcentaje para este valor aparece como 0)
La rama 3) nos indica Margen >335. Tiene 84 observaciones, de las cuales 77 "No" serían Ingresos 6700 (el porcentaje para este valor es 0,024)
Las ramas 2) y 3) se van dividiendo sucesivamente en más probabilidades.


>Si revisamos el gráfico de árbol podemos ver de manera más global que root para ingreso 5100 se divide entre "Yes" a >=335 y "No".
En "Yes" tenemos ingresos de 5100 con márgen de menos de 345, que finalmente nos divide en "Yes" para ingresos 4800 y "No" con ingresos 5100.
En el "No" que sale del root tenemos ingreso 6700 para el que se hace un primer split de margen >=295. Para "Yes" en esta opcion tenemos ingresos de 6700. Para "No", tenemos otro split de Ingresos 5800 con margen <245. Para "Yes" en este split tenemos un ingreso de 5500, para "No" tenemos otro split con ingresos de 5800. En este split si el margen es <275 los ingresos son 5800 y si "No" lo son, los ingresos son 6400.

>Este árbol da un porcentaje de aciertos del 5.263158 %, lo cual es muy bajo y poco útil.
>Los árboles de decision se componen de reglas sí-no, lo que crea limites de decisión que no son muy fluidos. 

>Este árbol tampoco es muy profundo, por lo que tal vez realizar una poda no serviría de mucho en la mejora de su porcentaje de aciertos.


## Pregunta 5

Analiza los modelos de la familia de SVM que pueden ser entrenados a través de la librería caret(enlace: http://topepo.github.io/caret/train-models-by-tag.html y buscar la familia SVM). 

Elige una variante y realiza las siguientes acciones
1) Describe las diferencias con la versión lineal de SVM (svmLinear)
2) Entrena un modelo con dicha variante elegida
3) MUestra la matriz de confusión del nuevo modelo
4) Compara las predicciones obtenidas por este modelo con la versión lineal de SVM entrenada en el apartado **Proceso de clasificación mediante SVM utilizando el paquete caret**.

## Respuesta 5 

>Estudiaremos la SVMRadial.

>A nivel general las SVM buscan maximizar el margen entre los puntos pertenecientes a distintos grupos a clasificar. Su objetivo es encontrar el hiperplano óptimo que maximiza el márgen entre clases del juego de datos de entrenamiento. Las SVM se apoyan en las funciones kernel para doblar el espacio de entrada y poder realizar cortes complejos de un hiperplano.

>Teniendo en cuenta esto, el SvmLineal trata el producto escalar de dos vectores, sin transformación del espacio de características. La función kernel, en este caso, respondería enteramente a lo que entendemos por producto escalar. 

>SVMRadial es de una función kernel no lineal. Se la conoce también como kernel de Gauss, generaliza el concepto de distancia entre vectores en lugar de su producto escalar. Está enfocada para modelar relaciones complejas y no lineales. Es una función muy dependiente del parámetro "y", por lo que deberemos tenerlo en cuenta para un posible sobreentrenamiento del juego de datos. 

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}

# Volvemos a revisar el modelo SVMLineal
svm.caret <- train(Comercial~., data=trainData, method = 'svmLinear', trControl = trainControl(method = "cv"))
svm.caret
# Realizamos las predicciones del modelo sobre el conjunto de test SVMLineal
preds_svm.caret<-predict(svm.caret, testData) 
# Matriz de confusión
confusionMatrix(preds_svm.caret,testData$Comercial) 

# Entrenamos el modelo SVM Radial
svm.radial <- train(Comercial~., data=trainData, method = 'svmRadial', trControl = trainControl(method = "cv"))
svm.radial
#Predicciones sobre SVM Radial
preds_svm.radial<-predict(svm.radial, testData)
# Matriz de confusión
confusionMatrix(preds_svm.radial,testData$Comercial) 

```

>Como vemos, obtenemos los mismos resutados con los dos modelos. El método CV aplicado en los modelos nos permite encontrar los parámetros óptimos, por lo que tal vez es el mejor resultado posible en los dos casos.
