---
title: 'Fundamentos de Data Science: PEC1 - Text Mining'
author: "Enrique Rocho Simon"
date: "Noviembre del 2022"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header:
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---

******

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



******
# Introducción
******
## Descripción de la PEC a realizar
La prueba está estructurada en 8 ejercicios teórico-prácticos que piden que se desarrolle la fase de preparación y estimación de un modelo utilizando un juego de datos.  

Deben responderse al menos 7 de los 8 ejercicios para poder superar la PEC. Para optar a la máxima nota tienen que responderse los 8 ejercicios.  

## Criterios de evaluación
**Ejercicios teóricos**  
Todos los ejercicios deben ser presentados de forma razonada y clara. No se aceptará ninguna respuesta que no esté claramente justificada.  

**Ejercicios prácticos**  
Para todas las PEC es necesario documentar en cada ejercicio práctico qué se ha hecho y cómo se ha hecho.  

Pregunta  | Criterio de valoración| Peso
---- | ------------- | ----
1  | Respuesta a la pregunta de forma correcta | 5%
2  | Primera visualización | 5%
2  | Segunda visualización | 5%
3  | Se realiza el gráfico solicitado| 10%
3  | Se contestan las cuestiones y se justifican | 5%
4  | Se describen los resultados que se solicitan | 15%
5  | Se contesta a la pregunta planteada | 10%
6  | Se entrena el modelo solicitado |15%
6  | Se describe el proceso solicitado  | 10%
7  | Se contesta a la cuestión planteada | 10%
8  | Se contesta a la cuestión planteada | 10%

## Formato y fecha de entega
El formato de entrega es: studentname-PECn.html  
Fecha de Entrega: 27/11/2022  
Se debe entregar la PEC en el buzón de entregas del aula  

******
# Base teórica
******
Esta práctica se basa en una de las aplicaciones de la **Minería de Textos**, que consiste en clasificar documentos en función de su temática. Esto es lo que se conoce como **Topic Model**. Para realizar la clasificación utilizaremos el algoritmo de aprendizaje automático K-Nearest Neighbors (K-NN).  

Por Topic Model entendemos procesos de aprendizaje automático que tienen por objetivo descubrir el tema subyacente en una colección de documentos. Generalizando un poco más, Topic Model busca patrones en el contenido de los documentos y lo hace en base a la frecuencia de aparición de palabras.  

El análisis que realizamos se basa en el hecho de que en documentos pertenecientes a un mismo tema aparecerán palabras que se repetirán con mayor frecuencia. Por lo tanto, el análisis plantea la clasificación de documentos utilizando como criterio las palabras que son más frecuentes en cada temática. Estas frecuencias se almacenarán en una matriz de datos, donde las variables serán las palabras y los registros los documentos, que será la base para que puedan trabajar los algoritmos de aprendizaje automático, que en esta práctica se centran en el K-NN.  

En este ámbito de conocimiento se basan los sistemas de clasificación documental, búsqueda de contenidos y sistemas de recomendación entre otros.

## Competencias
Las competencias que se trabajan en esta práctica son:  

* Capacidad de analizar datos textuales en R.  
* Capacidad de implementar el algoritmo K-NN para la clasificación de textos según temática.  

## Objetivos
* Asimilar correctamente los apartados 1.2.1, 1.2.2, 2.1, 3.2.1 y 3.2.2.   

## Recursos
Para realizar esta práctica recomendamos la lectura de lo siguiente:  

* Apartados 1.2.1, 1.2.2, 2.1, 3.2.1 y 3.2.2  del material didático **Análisis de datos para organizaciones**.  

* Los siguientes **Recursos en la web:**  

  -- [Journal Digital: Topic Modeling](http://journalofdigitalhumanities.org/2-1/topic-modeling-a-basic-introduction-by-megan-r-brett/)  
  -- [Wikipedia: Topic Modeling](http://en.wikipedia.org/wiki/Topic_model)  
  -- [Wikipedia: Sistemas de recomendación](http://es.wikipedia.org/wiki/Sistema_de_recomendaci%C3%B3n)  
  -- [CRAN: Text Mining Package](http://cran.r-project.org/web/packages/tm/tm.pdf)  


## Nota: Propiedad intelectual 

> A menudo es inevitable, al producir una obra multimedia, hacer uso de recursos creados por terceras personas. Es por lo tanto comprensible hacerlo en el marco de una práctica de los estudios de Informática, Multimedia y Telecomunicación de la UOC, siempre y cuando esto se documente claramente y no suponga plagio en la práctica. 

> Por lo tanto, al presentar una práctica que haga uso de recursos ajenos, se debe presentar junto con ella un documento en el que se detallan todos ellos, especificando el nombre de cada recurso, su autor, el lugar dónde se obtuvo y su estatus legal: si la obra está protegida por el copyright o se acoge a alguna otra licencia de uso (Creative Commons, licencia GNU, GPL ...). 
El estudiante deberá asegurarse de que la licencia no impide específicamente su uso en el marco de la práctica. En caso de no encontrar la información correspondiente tendrá que asumir que la obra está protegida por copyright. 

> Deberéis, además, adjuntar los ficheros originales cuando las obras utilizadas sean digitales, y su código fuente si corresponde.  

******
# Enunciado  
******
El objetivo es clasificar un conjunto de artículos de Reuters correspondientes a distintas temáticas: acquire,
crude, earn, grain, interest, money-fx, ship y trade. Se trata de temáticas relacionadas con inversiones financieras y fondos de inversión.  

Se utiliza un sistema de clasificación de documentos que se basa en el algoritmo de aprendizaje automático K-NN (K-Nearest Neighbors o K vecinos más próximos).    

Los datos están en el fichero data_reuter.txt. Este fichero contiene dos campos, el primero se corresponde con el tipo de temática (en total hay 8) y el segundo campo contiene el artículo relacionado. Entre las 8 temáticas se seleccionan 2 para realizar el análisis.

Para mostrar el funcionamiento del algoritmo de clasificación se utiliza un 70% de los artículos para entrenar el modelo de aprendizaje. Dicho algoritmo se aplica sobre el 30% de artículos restantes con el objetivo de predecir su temática.

******
# Apartados de la práctica
******
El código R que utilizaremos en la práctica se divide en apartados según las tareas que iremos realizando:  

* Lectura y selección de los datos  
* Creación del corpus, limpieza y acondicionado del texto 
* Generación de la Matriz de Términos (TDM-Terms Data Matrix).  
* Creación de la TDM.  
     + Subselecciones sobre TDM.  
* Descripción de la TDM.
* Creación de un data.frame apto para K-NN.  
* Construcción del Modelo de Clasificación con la función `knn()` del paquete "class" y con la función `train()` del paquete "caret".  
* Validación del Modelo de Clasificación.  

******
# Inicialización de variables
******
Instalamos los packages de R que necesitaremos para realizar la práctica:

* install.packages("tm")
* install.packages("plyr")
* install.packages("class")
* install.packages("ggplot2")
* install.packages("SnowballC")
* install.packages("wordcloud")
* install.packages("Rcpp")
* install.packages("caret")

Definimos el directorio de trabajo donde tendremos guardado el fichero de datos.

* setwd("ruta")

Para instalar los paquetes y definir el directorio de trabajo podéis eliminar los asteriscos delante de los **install.packages()** y **setwd()** seleccionarlos y ejecutarlos como comandos de R (Control+Intro).

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
## Cargamos los paquetes necesarios para ejecutar las funciones que se describen a continuación:
# Para la función Corpus()
library(tm)
# Para la función rbind.fill
library(plyr)
# Para la función knn()
library(class)

# En R una variable tipo factor es una variable categórica que puede contener tanto números como carácteres. Se trata de un tipo de variable muy útil para realizar tareas de modelización estadística.

# En R, por defecto, las columnas con carácteres no numéricos son tratadas como factores. Para evitarlo y garantizar que estas columnas sigan siendo consideradas carácteres, fijaremos el siguiente parámetro
options(stringsAsFactors = FALSE)

# Leemos los datos
data <- read.table('E:/Análisis de datos/Fundamentos Data Science/PEC1/data_reuter.txt', header=FALSE, sep='\t')
# Describimos los datos
## Cuantos hay en total
nrow(data)
# Cuantos hay para cada tipo de temática
table(data$V1)

library(ggplot2)
qplot(data$V1,xlab="Tematica", main = "Frecuencias")+ coord_flip()

# Finalmente seleccionamos dos temáticas: acq y earn
data2<-data[which(data$V1 %in% c("acq","earn")),]
## Cuantos hay en total
nrow(data2)
```

******
# Creación del corpus, limpieza y acondicionado del texto.
******
A continuación creamos un corpus para cada temática sobre los que se realizarán las siguietes tareas de **acondicionado de texto**:  

1. Eliminar signos de puntuación.  
2. Eliminar espacios en blanco innecesarios.  
3. Convertir todo el texto a minúsculas.  
4. Eliminar palabras sin significado propio.  
5. Eliminar números.  
6. Substituir las palabras derivadas por su palabra raíz.  

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# Creación del corpus de la temática acq
## Seleccionamos la temática
data_acq<-data2[(data2$V1=="acq"),]
## Construimos el corpus
source <- VectorSource(data_acq$V2)
corpus1 <- Corpus(source)
## Acondicionamos el corpus
### Convertir todo el texto a minúsculas
corpus1 <- tm_map(corpus1, content_transformer(tolower))
### Elimina números
corpus1 <- tm_map(corpus1, removeNumbers)
### Eliminar signos de puntuación
corpus1 <- tm_map(corpus1, removePunctuation)
###Eliminar espacios en blanco innecesarios
corpus1 <- tm_map(corpus1, stripWhitespace)
### Eliminar palabras sin significado propio
v_stopwords <- c(stopwords("english"),c("dont","didnt","arent","cant","one","also","said"))
corpus1 <- tm_map(corpus1, removeWords, v_stopwords)
### Eliminar signos de puntuación
corpus1 <- tm_map(corpus1, removePunctuation)
### Substituir las palabras derivadas por su palabra raíz
corpus1 <- tm_map(corpus1, stemDocument, language="english")

# Creación del corpus de la temática earn
## Seleccionamos la temática
data_earn<-data2[(data2$V1=="earn"),]
## Construimos el corpus
source <- VectorSource(data_earn$V2)
corpus2 <- Corpus(source)
## Acondicionamos el corpus
corpus2 <- tm_map(corpus2, content_transformer(tolower))
corpus2 <- tm_map(corpus2, removeNumbers)
corpus2 <- tm_map(corpus2, removePunctuation)
corpus2 <- tm_map(corpus2, stripWhitespace)
v_stopwords <- c(stopwords("english"),c("dont","didnt","arent","cant","one","also","said"))
corpus2 <- tm_map(corpus2, removeWords, v_stopwords)
corpus2 <- tm_map(corpus2, removePunctuation)
corpus2 <- tm_map(corpus2, stemDocument, language="english")
```
******
# Generación de la Matriz de Términos (TDM-Terms Data Matrix)
******
Seguidamente construimos una matriz de términos para cada temática para posteriormete unirlas en una misma lista.

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# Construimos la matrix de documentos de la temática acq
mat_acq <- TermDocumentMatrix(corpus1)
## Controlamos la dispersión (Sparsity): Número de celdas igual a cero respecto al total.
mat_acq<- removeSparseTerms(mat_acq,  0.80)
inspect(mat_acq)
mat_acq<-list(name="acq",mat=mat_acq)
mat_acq
str(mat_acq)

# Construimos la matrix de documentos de la temática earn
mat_earn <- TermDocumentMatrix(corpus2)
mat_earn<- removeSparseTerms(mat_earn,  0.80)
inspect(mat_earn)
mat_earn<-list(name="earn",mat=mat_earn)
mat_earn
str(mat_earn)

# Juntamos ambas matrices de términos en una misma lista
mat<-list(mat_acq, mat_earn)
str(mat)
```


******
## Visualizaciones sobre la matriz de palabras TDM  
******  
Con las dos matrices de frecuencias `mat[[1]]$mat` para acq y `mat[[2]]$mat` para earn, podemos realizar algunas visualizaciones básicas.  

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# Frecuencia de los 10 primeros términos en los 10 primeros documentos para ambos temas
inspect(mat[[1]]$mat[1:10,1:10])
inspect(mat[[2]]$mat[1:10,1:10])
# Frecuencia de los 10 primeros términos en todos los documentos del tema acq
inspect(mat[[1]]$mat[1:10,])
# Frecuencia de los términos en los documentos del tema earn
inspect(mat[[2]]$mat)
# Inventario de los primeros términos del del tema earn
head(mat[[2]]$mat$dimnames$Terms)
# Número de documentos del tema acq
nDocs(mat[[1]]$mat)
# Número de términos del tema acq
nTerms(mat[[1]]$mat)
# Visualizamos los términos con más de 100 apariciones en documentos de temática acq
findFreqTerms(mat[[1]]$mat, lowfreq=100)
```

******
# Descripción de la TDM.
******

******
## Representación gráfica de las frecuencias
******

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# Para acq
mmat_acq <- as.matrix(mat[[1]]$mat)
# Agregamos las frecuencias por términos y las ordenamos de mayor a menor  
v_acq <- sort(rowSums(mmat_acq), decreasing=TRUE)
# Creamos un data.frame con términos y frecuencias
d_acq <- data.frame(word=names(v_acq), freq=v_acq)
d_acq[,3]<-"acq"
# Hacemos lo mismo para earn
mmat_earn <- as.matrix(mat[[2]]$mat)
# Agregamos las frecuencias por términos y las ordenamos de mayor a menor  
v_earn <- sort(rowSums(mmat_earn), decreasing=TRUE)
# Creamos un data.frame con términos y frecuencias
d_earn <- data.frame(word=names(v_earn), freq=v_earn)
d_earn[,3]<-"earn"

# Concatenamos las dos matrices
fdata<-rbind(d_acq,d_earn)
colnames(fdata)
colnames(fdata)<-c("Palabra", "Frecuencia", "Tematica")

# Gráfico de barras con las palabras más frecuentes
library(ggplot2)

ggplot(subset(fdata, Frecuencia>500),aes(Palabra,Frecuencia,fill=Tematica))+geom_bar(stat="identity",position=position_dodge())+theme(axis.text.x=element_text(angle=45, hjust=1))
```

******
## Construcción de una nube de palabras
******
Podemos construir una nube de palabras para la matriz de términos con ambas temáticas. 
```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# Cargamos la librería wordcloud
require(wordcloud)
# Construimos la nube de palabras o términos, para ello primero seleccionamos los que tienen una frecuencia superior a 500
sfdata<-subset(fdata, Frecuencia>500)
wordcloud(sfdata$Palabra, fdata$Frecuencia,min.freq=500,random.color=FALSE, colors=rainbow(3))

```

******
# Creación de un data.frame apto para K-NN
******
A continuación se construirá un data.frame en el que las columnas representan Términos, las filas Documentos y las celdas Frecuencias del término o palabra en cada documento.  


```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# Creación de un data.frame apto para K-NN
# Para acq
s.mat_acq <- t(data.matrix(mat[[1]]$mat))
# La convertimos en data.frame que vendría a ser como un formato excel (filas, columnas y celdas con valores)  
# En este data.frame, tenemos que cada fila es un documento, cada columna una palabra y las celdas contienen la frecuencia en que cada palabra aparece en cada documento.
s.df_acq <- as.data.frame(s.mat_acq, stringsAsFactors = FALSE)
nrow(s.df_acq)
# En la última columna colocaremos el Tema de cada documento tdm[["name"]. Para ello usaremos dos funciones cbind() y rep()  

# Recordemos que en la lista TDM habíamos almacenado el tema en el valor "name"
# Mediante la función rep() repetiremos el tema del documento tantas veces como filas hay en el data.frame 
Tema <- rep(mat[[1]]$name, nrow(s.df_acq))
s.df_acq<-cbind(s.df_acq,Tema)

# Para earn
s.mat_earn <- t(data.matrix(mat[[2]]$mat))
# La convertimos en data.frame que vendría a ser como un formato excel (filas, columnas y celdas con valores)  
# En este data.frame , tenemos que cada fila es un documento, cada columna una palabra y las celdas contienen la frecuencia en que cada palabra aparece en cada documento.
s.df_earn <- as.data.frame(s.mat_earn, stringsAsFactors = FALSE)
# En la última columna colocaremos el Tema de cada documento tdm[["name"]. Para ello usaremos dos funciones cbind() y rep()  

# Recordemos que en la lista TDM habíamos almacenado el tema en el valor "name"
# Mediante la función rep() repetiremos el tema del documento tantas veces como filas hay en el data.frame 
Tema <- rep(mat[[2]]$name, nrow(s.df_earn))
s.df_earn<-cbind(s.df_earn,Tema)

# Utilizamos la función rbind.fill() para concatenar las filas de dos data frame con distinta dimensión y pone NA en las casillas donde no hay información.
pila <-rbind.fill(s.df_acq, s.df_earn)
pila[is.na(pila)] <- 0

# Cada fila representa un documento, cada columna una palabra y las celdas son la frecuencia de aparición de esa palabra en ese documento.
## Tenemos 4436 documentos 
nrow(pila)
## Tenemos 48 palabras
ncol(pila)
```


******
## Construcción del Modelo de clasificación utilizando la función `knn` del paquete "class"
******
Construimos un **juego de datos de entrenamiento** con el 70% de los documentos, es decir, 3106 documentos.    
Así mismo construiremos un **juego de datos de pruebas** con el 30% de documentos restante, es decir 1330 documentos.  

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# Fijamos una semilla para poder repetir la práctica obteniendo los mismos resultados. 
set.seed(111)

# 70% de los documentos para entrenamiento
entrena.idx <- sample(nrow(pila), ceiling(nrow(pila) * 0.7))
# El resto de documentos para pruebas
test.idx <- (1:nrow(pila))[-entrena.idx]
```

Para poder aplicar el algoritmo de aprendizaje por vecindad K-NN necesitamos realizar unas pequeñas adaptaciones.  
Éstas consisten en separar por un lado los temas y por otro la matriz de frecuencias.  

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# guardamos por un lado los temas
tema <- pila[, "Tema"]
# y por otro lado el resto de palabras
pila.nl <- pila[, !colnames(pila) %in% "Tema"]
```

**Aplicamos el modelo K-NN**, pasándole como parámetros la matriz de frecuencias de los documentos de entrenamiento, la matriz de frecuencias de los documentos de pruebas y los temas de los documentos de entrenamiento.  

Los temas de los documentos de prueba no se los pasamos, porque precisamente es lo que el algoritmo debe predecir.  

Recordamos que **el objetivo del modelo será el de predecir el tema de los documentos de pruebas**.  

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# Modelo KNN
knn.pred <- knn(pila.nl[entrena.idx, ], pila.nl[test.idx, ], tema[entrena.idx])
```


******
## Construcción del Modelo de clasificación utilizando la función `train` del paquete "caret"
******

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
library(caret)
# Creamos la base de datos de entrenamiento con la dependiente (tema) y las explicativas (palabras)
dat_train<-cbind(pila.nl[entrena.idx, ],tema[entrena.idx])
# Definimos una malla de valores para k
knnGrid <-  expand.grid(k = c(1:3))
# Modelo KNN
knn.caret <- train(`tema[entrena.idx]`~., data=dat_train,method = "knn",tuneGrid = knnGrid)
knn.caret
```

******
# Validación del Modelo de clasificación
******

Una vez aplicado el modelo K-NN sobre el juego de documentos de prueba, podemos utilizar una **matriz de confusión** para valorar el nivel de acierto del modelo.  

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# Modelo KNN
knn.pred <- knn(pila.nl[entrena.idx, ], pila.nl[test.idx, ], tema[entrena.idx])
# Matriz de confusión
# Las filas son predicciones y las columnas son observaciones reales
conf.mat <- table("Predicción" = knn.pred,"Real" = tema[test.idx])
conf.mat
```
Observamos como K-NN, de los 1330 documentos, ha clasificado correctamente 1292:  

* 460 documentos como acq. 
* 830 documentos como earn.  

y ha fallado en 40 documentos, puesto que los ha clasificado 10 como acq cuando en realidad eran earn y 30 como earn que en reladad eran acq.  

Para evaluar la capacidad predictiva del algoritmo utilizamos dos medidas, que hemos denominado ratio1 y rati2.  

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
ratio1 <- (conf.mat[1,1]/(conf.mat[1,1]+conf.mat[2,1]))*100
ratio1
```
```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
ratio2 <- (conf.mat[2,2]/(conf.mat[1,2]+conf.mat[2,2]))*100
ratio2
```

******
## Matriz de confusión con el paquete "caret"
******

Obtenemos una matriz de confusión más completa. Además de la precisión, la sensibilidad y la especificidad, esta matriz de confusión proporciona estadísticos que nos ayudan a valorar la capacidad informativa del modelo.

Es importante tener en cuenta que la categoría sobre la que calcula la probabilidad es la menor, o en caso de alfanuméricas la primera en el alfabeto. En este caso es acq (respecto a earn), esto lo indica al final de la matriz de confusión.

|          |	Reference      	|
|:---------|:------|:---------|
|Predicted |	Event|	No Event|
|Event     |A	     |B         |
|No Event  |C      |D         |


Los resultados son:

Sensitivity = A/(A+C)

Specificity = D/(B+D)

Prevalence = (A+C)/(A+B+C+D)

PPV = (sensitivity * prevalence)/((sensitivity * prevalence) + ((1-specificity) * (1-prevalence)))

NPV = (specificity * (1-prevalence))/(((1-sensitivity) * prevalence) + ((specificity) * (1-prevalence)))

Detection Rate = A/(A+B+C+D)

Detection Prevalence = (A+B)/(A+B+C+D)

Balanced Accuracy = (sensitivity+specificity)/2

Precision = A/(A+B)

Además de lo anterior la matriz de confusión también informa del 

- porcentaje de acierto: Accuracy = (A+D)/(A+B+C+D)

- cociente no informativo (NIR): No Information Rate = (A+C)/(A+B+C+D) = Prevalence

- p-valor para el contraste de la $H_0: Accuracy>NIR$: $P-Value [Acc > NIR]$, es una medida de capacidad informativa del modelo. **Cuanto menor es el p-valor mejor**

- Estadístico Kappa: k= (Accuracy-Random Acc)/(1-Random Acc), donde Random Acc=(p1*p2)+(1-p1)*(1-p2), 
con p1=Prevalence y p2=Detection Prevalence. **Cuanto más próxima a 1 se sitúe el valor de Kappa mayor poder informativo del modelo**.

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
dat_test<-cbind(pila.nl[test.idx, ],tema[test.idx])
preds_knn<-predict(knn.caret, dat_test) 
# Matriz de confusión
confusionMatrix(preds_knn,as.factor(dat_test$`tema[test.idx]`))
```

******
# Ejercicios
******

## Ejercicio 1:
En el apartado "Generación de la Matriz de Términos", un valor a controlar es la "Sparsity" que se fija en 0.80. Describa como se calcula el valor de la Sparsity que finalmente se consigue en ambas matrices de términos. ¿Qué implica que la "Sparsity" en  la matriz de términos asociada a la temática earn sea menor?.

## Respuesta 1:


>El valor "Sparsity" o dispersión de los términos nos indicará, si tiene un nivel alto, que habrán muchos términos que no aparecen en el resto de documentos (nos dará muchas celdas igual a 0 respecto al total). Nos indicará cuantos términos están en un documento pero en otros no.

>En el caso de un 0.80, nos indicará que hay un 80% de términos de términos que no aparecen en el resto de documentos.

>Para calcular el valor de la "Sparsity", se divide el total de celdas (filas por columnas) de apariciones de cada término y se divide entre el total de celdas con ceros, es decir entre el total de celdas que indican términos que no aparecen en otros documentos.

>Para conseguir un valor de "Sparsity" del 80% se ha usado la función removeSparseTerms().

>En el caso de la temática "acq", si realizamos un inspect de mat_acq antes de utilizar la función removeSparseTerms(),  obtendríamos 1596 documentos y 7907 términos. Tendríamos un total de 12544124 ceros sobre un total de 12619572 celdas. Esto nos da una Sparsity del 99%, lo que significa que un 99% de celdas serían 0.

>En el caso de la temática "earn", si realizamos un inspect de mat_acq antes de utilizar la función removeSparseTerms(), obtendríamos 2840 documentos y 7782 términos. Tendríamos un total de 22017017 ceros sobre un total 22100880. Esto nos daría una Sparsity del 100% (en realidad sería de un 99.6%, bastante cercano al 100%).

>Con la función removeSparseTerms se busca reducir esta dispersión.

>En el caso de la temática "acq" para conseguir un 80% de dispersión máxima aceptada, tendríamos que multiplicar el total de documentos por (1-80%). Es decir:
>1596*(1-0.8)= 319.2
> Se aceptaría, por tanto, que cada término apareciera en al menos 320 documentos.
> En el caso de "acq", pasamos de 7907 términos a 20 términos en 1596 documentos (total de 31920). Ahora tendremos 20173 de celdas a 0, lo que nos dará una sparsity del 63% como nos indica el inspect

>En el caso de la temática "earn", para conseguir un 80% de dispersión máxima aceptada, tendríamos que multiplicar el total de documentos por (1-80%). Es decir:
>2840*(1-0.8)= 568
> Se aceptarían que cada término apareciera en al menos 568 documentos.
> Pasaríamos entonces de 7782 términos a 22 términos en 2840 dcumentos (total de 62480 celdas). Tendríamos ahora 38001 celdas a 0, lo que daría una "sparsity" del 61% aprox como indicará la funcion inspect.

> Conseguir una menor "Sparsity" en "earn" ( o en cualquier otra temática), supone reducir la cantidad de términos de los que vamos a disponer, al condicionar a que cada término aparezca en al menos una cantidad de documentos determinada. Esto puede suponer una pérdida de información, lo que deberemos tener en cuenta para ajustar esta "Sparsity". En el caso de "earn" en concreto pasaríamos de  7782 términos a 22, por lo que tendríamos que revisar si esta reducción supone una pérdida muy drástica de información.

## Ejercicio 2:
En el apartado "Visualizaciones sobre la matriz de palabras TDM" se muestron algunos ejemplos de visualización de distintas secciones de la matriz de términos. Visualizad los 10 primeros términos y los 15 primeros documentos en la temática "acq" y todos los términos de los 5 primeros documentos de la temática "earn". Posteriormente visualizar aquellas palabras relacionadas con esta misma temática y con frecuencia menor a 500 y mayor a 5.

## Respuesta 2:
> 

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
#Visualizad los 10 primeros términos y los 15 primeros documentos en la temática "acq":
inspect(mat[[1]]$mat[1:10,1:15])
#Todos los términos de los 5 primeros documentos de la temática "earn":
inspect(mat[[2]]$mat[,1:5])
#Visualizar aquellas palabras relacionadas con esta misma temática (earn) y con frecuencia menor a 500 y mayor a 5:
findFreqTerms(mat[[2]]$mat, lowfreq=5, highfreq=500)

```


## Ejercicio 3:
En el apartado "Descripción de la TDM" se construye un gráficos de barras con las palabras con una frecuencia mayor que 500 en ambas temáticas.
Construya un gráfico de barras similar, con las palabras con una frecuencia mayor que 100, con las barras apiladas y en posición horizontal. ¿Qué implica la existencias de estas barras con un solo color?.


## Respuesta 3: 

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}


# Cargamos la librería:
library(ggplot2)

# Creación del gráfico de barras apiladas, en posición horizontal:
ggplot(subset(fdata, Frecuencia>100))+ geom_col(aes(Palabra,Frecuencia,fill=Tematica))+coord_flip()
```

¿Qué implica la existencias de estas barras con un solo color?

>Hay barras que aparecen en un solo color y otras en dos, esto se debe a que hemos aplilado las barras. 
>Las barras que corresponden a términos que aparecen en las dos temáticas, aparecerán en dos colores, teniendo una predominancia mayor en la barra el color que pertenezca a la temática en la que aparece más vecez el término.
>Si en algun caso la barra aparece solo en un color, significa que el término correspondiente solo aparece en una de las dos temáticas.
> El problema de apilar las barras de esta manera, es que es más difícil conocer el valor de los términos en los que coinciden los dos colores, ya que el punto de base no será 0, sino que será el final de la barra sobre la que se sitúa, por lo que perderemos esta perspectiva. Es decir, podremos ver el total de un término en las dos temáticas, pero es mucho más confuso ver cuantas veces aparece cada término por temática.


## Ejercicio 4: 
Se ha construido un modelo de clasificación con la función `knn()` y con la función `train()`. Describa las diferencias que hay en el tipo de entrenamiento del modelo realizado con cada función.

## Respuesta 4: 

> En el modelo knn el objetivo será predecir el tema de los documentos de pruebas.
> K-NN no genera un modelo fruto del aprendizaje con datos de entrenamiento, sino que el aprendizaje sucede
en el mismo momento en el que se prueban los datos de test. A este tipo de algoritmos se les llama lazy learning methods.


>En la funcion knn() del paquete class, para cada columna del juego de datos de pruebas, se encuentra el k más cercano (en distancia Euclidiana) al juego de entrenamiento y la clasificación se decide por voto mayoritario, rompiendo los empates de manera aleatoria. Si hay empates para el k vector más cercano, todos los candidatos se incluyen en el voto. A parte de los argumentos train y test, incluye "cl" (factor de clasificaciones correctas del juego de entrenamiento), "k" (número de vecinos considerados), "l" (voto mínimo para una decisión definitiva), "prob" (si es True la proporción de votos para la clase ganadora aparace con el atributo prob), entre otros.

>En el caso de este ejercicio, se construye un juego de datos de entrenamiento con el 70% de los documentos y el de pruebas con el 30% restante y se realizan adaptaciones, como separar por un lado los temas y por otro la matriz de frecuencias. A la función knn() se le pasan los argumentos de entrenamientos para palabras y temas, y test o prueba para palabras. No se proporciona test para tema, ya que es esto lo que se quiere predecir. 

>Una vez realizadas las matriz de confusión para el modelo knn, se obtienen unos resultados un poco diferentes a los del enunciado.

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
#Real
#Predicción acq earn
#      acq  471   15
#      earn  19  825
```

>De los 1330 documentos, en este caso, se han clasificado correctamente 1295 (471 para acq y 825 para earn). Se han clasificado incorrectamente 34 (15 como earn que debían ser acq, y 19 como acq que debían ser earn).

>Se han revisado también los dos ratios para evaluar la capacidad predictiva del modelo y se ha obtenido:

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
#ratio1= 96.12245
#ratio2= 98.21429
```

>Respecto a la funcion train(), ésta establece una malla de parámetros para afinar rutinas de clasificacion y regresión, adapta cada modelo, calcula y hace resampling según medidas de rendimiento.
Para un modelo en concreto la malla de parámetros se crea y el modelo se entrena en datos que tienen pequeñas diferencias para cada combinación candidata de parámetros de afinación.
A través de cada juego de datos, el rendimiento se calcula y la media y desviación estandard se resume para cada combinación. La combinación que tiene la estadística de resampling óptima se elige como modelo final y el juego de datos completo se usa para ajustar un modelo final.

>Pueden usar argumentos como "tunelength" para controlar cuantos valores de los parametros son evaluados, "tunegrid" cuando se desean unos valores concretos, "method" controla el tipo de resampling, entre otros.

>En el caso de este ejercicio, se ha creado una base de datos para las palabras y otro para los temas. Después se ha creado la malla con los valores k de 1 a 3, y se ha aplicado la funcion train() con los parámetros de entrenamiento, el metodo knn, y como tunegrid la malla creada. 
Una vez ejecutada la función train se han obtenido los siguientes resultados:

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
#  k  Accuracy   Kappa    
#  1  0.9688884  0.9324270
#  2  0.9665467  0.9274647
#  3  0.9665770  0.9276613
```

>Para seleccionar el modelo óptimo se ha usado el parámetro precisión, usando el valor más alto (que en este caso es k=1)

> En este caso, para el paquete "caret" la matriz de confusión da muchos más resultados que para el paquete "class", ya que además de la precisión, la sensibilidad y la especificidad, esta matriz de confusión proporciona estadísticos que nos ayudan a valorar la capacidad informativa del modelo.
Los resultados que nos da son:

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
#          Reference
#Prediction acq earn
#      acq  471   14
#      earn  19  826
                                          
#              Accuracy : 0.9752          
#                 95% CI : (0.9653, 0.9829)
#    No Information Rate : 0.6316          
#    P-Value [Acc > NIR] : <2e-16          
                                          
#                  Kappa : 0.9466          
                                          
# Mcnemar's Test P-Value : 0.4862          
                                          
#           Sensitivity : 0.9612          
#            Specificity : 0.9833          
#        Pos Pred Value : 0.9711          
#        Neg Pred Value : 0.9775          
#            Prevalence : 0.3684          
#        Detection Rate : 0.3541          
#  Detection Prevalence : 0.3647          
#     Balanced Accuracy : 0.9723          
                                          
#       'Positive' Class : acq   
```

> Esta función en "caret" ha realizado una predicción solo un poco mejor que la de knn() con "class", ya que solo ha fallado en 33 documentos, respecto a los 34 de knn(). La precisión es por tanto solo levemente más alta. 

>Sin embargo el paquete Caret nos proporciona más información en su matriz de confusión, incluyendo kappa (que cuanto más cercana a 1 sea, nos indicará un mayor poder informativo del modelo) o el p-valor (que también mide el valor informativo del modelo, pero en este caso tiene que ser lo más bajo posible).

>Las estadísticas sensitivity, specificity, positive predictive value and negative predictive value se calculan utilizando el argumento "positive" que corresponde a un resultado positivo, en el que si hay dos niveles de factores, el primero será usado como resultado positivo.

>En general parece más óptimo utilizar el paquete caret y función train() en este caso, ya que la precisión es un poco mayor y nos proporciona una matriz de confusión más detallada e informativa.



## Ejercicio 5: 
En el apartado "Validación del Modelo de clasificación" se utiliza la función "knn" para clasificar los documentos según temática. Esta función por defecto supone que el número de vecinos a evaluar es igual a 1. ¿Qué dificultad añadida podría tener seleccionar un número de vecinos igual a 2?.   

## Respuesta 5: 

> Knn es muy sensible a la escala de datos al depender de computos de distancia. Para escalas más altas, las disrancias calculadas pueden ser muy altas y producir malos resultados.

>El algoritmo selecciona las k instancias de entrenamiento más cercanas y se asigna la instancia a la clase más frecuente entre las k instancias seleccionadas como más cercanas. El num k indicaría el número de vecinos cercanos.

>El valor k suele fijarse tras un proceso de prueba con varias instancias dado que podemos obtener resultados muy distintos según el valor de k. 

>En el caso de la matriz de confusión de "caret", hemos obtenido una menor precisión y valor kappa para k=2:

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
#  k  Accuracy   Kappa    
#  1  0.9688884  0.9324270
#  2  0.9665467  0.9274647
```

>Añadir un k mayor supone también incrementar la lentitud del proceso de computación, ya que cada instancia de prueba es comparada con todo el juego de datos de entrenamiento y será la bondad de los resultados lo que determine el ajuste de k. 

> Por otro lado, valores bajos de k pueden hacer el modelo más sensible al ruido y llevar a decisión más inestables, seria un modelo con más varianza, más flexible. 

>Igualmente Usar un valor par en k no es recomendado porque hay riesgo de empate en la decisión de la clase, por lo que se suelen usar valores impares.


## Ejercicio 6: 
Del fichero inicial seleccionar dos temáticas distintas a las del enunciado y entrenar un k-NN utilizando la función `train()` que permita clasificar nuevos artículos en una de ambas temáticas. En la función `train()` defina una malla de valores para K impares entre 1 y 15, comente cuál es el valor óptimo y describa detalladamente como se realizaría una predicción de un nuevo dato.


## Respuesta 6: 

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}


## Cargamos los paquetes necesarios para ejecutar las funciones que se describen a continuación:
# Para la función Corpus()
library(tm)
# Para la función rbind.fill
library(plyr)
# Para la función knn()
library(class)

options(stringsAsFactors = FALSE)

# Leemos los datos
data <- read.table('E:/Análisis de datos/Fundamentos Data Science/PEC1/data_reuter.txt', header=FALSE, sep='\t')

#Cuantos documentos hay en total
nrow(data)

# Cuantos hay para cada tipo de temática
table(data$V1)

library(ggplot2)
qplot(data$V1,xlab="Tematica", main = "Frecuencias")+ coord_flip()

# Las temáticas que vamos a seleccionar son: "grain" y "trade"
data2<-data[which(data$V1 %in% c("grain","trade")),]
# Cuantos docs hay para las temáticas
nrow(data2)

# Ahora creamos el corpus de temática "grain"
## Seleccionamos la temática
data_grain<-data2[(data2$V1=="grain"),]
## Construimos el corpus
source <- VectorSource(data_grain$V2)
corpus1 <- Corpus(source)
## Acondicionamos el corpus
corpus1 <- tm_map(corpus1, content_transformer(tolower))
corpus1 <- tm_map(corpus1, removeNumbers)
corpus1 <- tm_map(corpus1, removePunctuation)
corpus1 <- tm_map(corpus1, stripWhitespace)
v_stopwords <- c(stopwords("english"),c("dont","didnt","arent","cant","one","also","said"))
corpus1 <- tm_map(corpus1, removeWords, v_stopwords)
corpus1 <- tm_map(corpus1, removePunctuation)
corpus1 <- tm_map(corpus1, stemDocument, language="english")

# Creación del corpus de la temática "trade"
## Seleccionamos la temática
data_trade<-data2[(data2$V1=="trade"),]
## Construimos el corpus
source <- VectorSource(data_trade$V2)
corpus2 <- Corpus(source)
## Acondicionamos el corpus
corpus2 <- tm_map(corpus2, content_transformer(tolower))
corpus2 <- tm_map(corpus2, removeNumbers)
corpus2 <- tm_map(corpus2, removePunctuation)
corpus2 <- tm_map(corpus2, stripWhitespace)
v_stopwords <- c(stopwords("english"),c("dont","didnt","arent","cant","one","also","said"))
corpus2 <- tm_map(corpus2, removeWords, v_stopwords)
corpus2 <- tm_map(corpus2, removePunctuation)
corpus2 <- tm_map(corpus2, stemDocument, language="english")

# Construimos la matriz de términos de la temática "grain"
mat_grain <- TermDocumentMatrix(corpus1)
inspect(mat_grain)

# Controlamos la dispersión (Sparsity): Número de celdas igual a cero respecto al total.
mat_grain<- removeSparseTerms(mat_grain,  0.80)
inspect(mat_grain)

mat_grain<-list(name="grain",mat=mat_grain)
mat_grain
str(mat_grain)

# Construimos la matriz de documentos de la temática "trade"
mat_trade <- TermDocumentMatrix(corpus2)
inspect(mat_trade)

mat_trade<- removeSparseTerms(mat_trade,  0.80)
inspect(mat_trade)

mat_trade<-list(name="trade",mat=mat_trade)
mat_trade
str(mat_trade)

# Juntamos ambas matrices de términos en una misma lista
mat<-list(mat_grain, mat_trade)
str(mat)

# Guardamos por un lado los temas
tema <- pila[, "Tema"]
# Y por otro lado el resto de palabras
pila.nl <- pila[, !colnames(pila) %in% "Tema"]



# Creación de un data.frame apto para K-NN
# Para "grain":
s.mat_grain <- t(data.matrix(mat[[1]]$mat))
# La convertimos en data.frame:
s.df_grain <- as.data.frame(s.mat_grain, stringsAsFactors = FALSE)
nrow(s.df_grain)
# En la última columna colocaremos el Tema de cada documento tdm[["name"] con cbind() y rep()
Tema <- rep(mat[[1]]$name, nrow(s.df_grain))
s.df_grain<-cbind(s.df_grain,Tema)

# Para "trade"
s.mat_trade <- t(data.matrix(mat[[2]]$mat))
# La convertimos en data.frame:
s.df_trade <- as.data.frame(s.mat_trade, stringsAsFactors = FALSE)
# Colocaremos el Tema de cada documento tdm[["name"] con cbind() y rep()
Tema <- rep(mat[[2]]$name, nrow(s.df_trade))
s.df_trade<-cbind(s.df_trade,Tema)

# Con la función rbind.fill() concatenamos las filas de dos data frame con distinta dimensión y ponemos NA en las casillas donde no hay información
pila <-rbind.fill(s.df_grain, s.df_trade)
pila[is.na(pila)] <- 0


## Tenemos 292 documentos 
nrow(pila)
## Tenemos 76 palabras
ncol(pila)


# Fijamos una semilla para poder repetir la práctica obteniendo los mismos resultados. 
set.seed(111)

# Fijamos el 70% de los documentos para entrenamiento
entrena.idx <- sample(nrow(pila), ceiling(nrow(pila) * 0.7))
# El resto de documentos para pruebas
test.idx <- (1:nrow(pila))[-entrena.idx]
```



```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# Uso de "knn" para evitar error al aplicar "train" con "caret"
knn.pred <- knn(pila.nl[entrena.idx, ], pila.nl[test.idx, ], tema[entrena.idx])


#Utilizaremos el paquete "Caret" para poder usar la función train()
library(caret)
# Creamos la base de datos de entrenamiento con la dependiente (tema) y las explicativas (palabras)
dat_train<-cbind(pila.nl[entrena.idx, ],tema[entrena.idx])
# Definimos una malla de valores, que en este caso tiene que ser impar y del 1 al 15:
knnGrid <-  expand.grid(k = c(seq(1,15, by = 2)))

# Ahora usamos la función train()
knn.caret <- train(`tema[entrena.idx]`~., data=dat_train,method = "knn",tuneGrid = knnGrid)
knn.caret

#Comente cuál es el valor óptimo y describa detalladamente como se realizaría una predicción de un nuevo dato:

#El valor óptimo según train() ha sido k=1


#Usaremos la Matriz de confusión para ver cómo se clasifican los términos de prueba.Primero asignaremos, los test a dat_test
dat_test<-cbind(pila.nl[test.idx, ],tema[test.idx])

#Con el siguiente código usamos la función predict para aplicar el modelo knn.caret que hemos creado con train y lo aplica sobre dat_test que es el set de datos que usaremos para realizar la prueba:
preds_knn<-predict(knn.caret, dat_test)

# La matriz de confusión se lanzaría con este código, sin embargo a pesar de funcionar en R, da error al exportar a R Markdown:
#confusionMatrix(preds_knn,as.factor(dat_test$`tema[test.idx]`))

#El resultado que debería dar es:

#Confusion Matrix and Statistics

#          Reference
#Prediction grain trade
#    grain    10     1
#   trade     1    75
                                          
#               Accuracy : 0.977           
#                 95% CI : (0.9194, 0.9972)
#    No Information Rate : 0.8736          
#    P-Value [Acc > NIR] : 0.0007181       
                                          
#                  Kappa : 0.8959          
                                          
# Mcnemar's Test P-Value : 1.0000000       
                                          
#            Sensitivity : 0.9091          
#            Specificity : 0.9868          
#         Pos Pred Value : 0.9091          
#         Neg Pred Value : 0.9868          
#             Prevalence : 0.1264          
#         Detection Rate : 0.1149          
#   Detection Prevalence : 0.1264          
#      Balanced Accuracy : 0.9480          
                                          
#       'Positive' Class : grain   

```
>Como vemos, el modelo ha clasificado correctamente 85 de 87 documentos. Se han clasificado incorrectamente 2 codumentos: 1 documento ha sido clasificado como "trade" cuando debería ser "grain" y 1 documento ha sido clasificado como "grain" cuando debería ser "trade". Se muestra una precisión del 97,7%

Describa detalladamente como se realizaría una predicción de un nuevo dato:

>Si quisieramos predecir otro valor para el modelo obtenido, usaríamos la función predict(), usando knn.caret como modelo, pero usaríamos "new data= " para incluir el dato que quisieramos predecir en lugar de dat_test:

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# predict(knn.caret, new data= ) 
```


> 

## Ejercicio 7: 
¿En qué distancia se basa el algoritmo K-NN que se define en la función knn() de R que se ha utilizado para entrenar el modelo?. Realizad una o más críticas a dicha distancia y describid cómo podría corregirse.


## Respuesta 7: 

> Se utiliza la distancia euclidiana, que es la que coincide con lo que nuestra intuición entiende por distancia (podría ser llamada distancia ordinaria). El inconveniente que tiene es que no tiene en cuenta las diferentes unidades de medida en que pueden estar expresadas las diferentes variables de las dimensiones. 

> Para solucionar este punto, se podría utilizar la distancia estadística (o de Gauss), que normaliza las variables, eliminando la distorsión creada por las diferentes unidades de medida. Sin embargo, esta distancia también tiene el problema de que no tiene en cuenta la correlación de las variables, por lo que si hay alguna corralación entre ellas, la influencia entre ellas no quedaría reflejada con este tipo de distancia.

> Por eso, tambien se puede usar la distancia de Mahalanobis, que sí que corrige la distorsión provocada por la correlación de las variables.

> Una de las maneras de corregir el problema de la desnormalización sería usar la función kNN también del paquete "class" que permite normalizar los datos:
> kNN(form, train, test, norm = T, norm.stats = NULL, ...)

>El parámetro norm, permite definir si los datos de entrenamiento deberían ser normalizados antes de obtener las predicciones k-NN.
>El parámetro norm.stats permite proporcionar la centralidad y la propagación (spread) que tendrá en cuenta la normalización.


## Ejercicio 8: 

¿Afirmaría que en todos los modelos entrenados en los ejercicios de la práctica el algoritmo KNN es determinista?

## Respuesta 8: 

> Un modelo determinista es aquel donde las mismas entradas o condiciones iniciales producirán invariablemente las mismas salidas o resultados, no contemplandose la existencia de azar o incertidumbre en el proceso modelado mediante ese modelo. 
> El algoritmo knn es muy sensible a la variable k, ya que con valores distintos de k podemos obtener resultados muy distintos, lo que hace necesario que este valor se fije después de realizar pruebas con varias instancias. 
> Sin embargo el resultado para cada k será el mismo, no variará con cada intento, por lo tanto diríamos que el algorítmo KNN sí es determinista.
> Por otro lado, si comparamos los resultados de precisión de knn al usar knn() de class y al usar train() de caret, veremos que estos son diferentes, y que además train() ha clasificado un poco mejor algunos documentos. Por tanto el algoritmo en si es determinista, pero usar diferentes paquetes y funciones de r puede causar variaciones en los resultados con condiciones similares.
